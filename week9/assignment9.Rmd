# 라이브러리와 데이터 불러오기
```{r}
list(rm=list())
library(caret)
names(getModelInfo())

# Load data from Hadley Wickham on Github - Vehicle data set and predict 6 cylinder vehicles
library(RCurl)

# Read the data file on local disk
getwd()
setwd(".")

data <- read.csv("coupon.csv")
data
str(data)
```

# 데이터 전처리 및 타입 변환
레벨이 6개보다 많은 것들을 수치형으로 변환한다.
```{r}
# 결측치 확인
table(is.na(data))

# factor로 전부 바꾸어 factor의 레벨을 확인 (명목형인지 연속형인지 구분)
temp <- data
temp[sapply(temp, is.integer)] <- lapply(temp[sapply(temp, is.integer)], 
                                       as.factor)
temp[sapply(temp, is.character)] <- lapply(temp[sapply(temp, is.character)], 
                                       as.factor)
str(temp) # 결과 : 수치형으로 만들 것들 - age(8 레벨), occupation(25 레벨), income(9 레벨)

# 수치형 변수들은 수치형으로 변환
data <- temp
data$age <- as.integer(data$age)
data$occupation <- as.integer(data$occupation)
data$income <- as.integer(data$income)

# 레벨이 1인 toCoupon_GEQ5min는 속성에서 제거하기 (값이 하나로만 이루어진 속성이므로 Y에 영향을 주지 않는다)
data <- data[, -21]
```

# 데이터 분포 탐색
```{r}
# Box Plot을 통해 데이터 분석 (극단치 여부) -- 전부 명목형 변수인 버전으로 분석
boxplot(temp)
prop.table(table(data$Y))
str(data)
```

# 상관계수 구하기
크래머V 계수를 통해 명목형 속성들의 Y에 대한 상관도를 파악
cramer'V를 구하는 실행시간이 좀 걸리니 기다리도록 하자.
```{r}
library(creditmodel)
# cramer's V를 통해 명목형 변수들로 상관계수표 출력
char_x_list = get_names(dat = data, types = c('factor'), get_ex = FALSE)
char_x_list # 명목형, 범주형 변수 리스트
cor <- char_cor(dat = data[char_x_list])
cor

cramerV_cor <- (cor[22, ])[-22] # Y에 대한 명목형 변수들의 상관계수
```
피어슨 상관계수를 통해 수치형 속성들의 Y에 대한 상관도를 파악
```{r}
library(dplyr) # 피어슨 상관계수
library(psych)
library(corrplot) # 상관계수를 plot

# 수치형 변수들을 파악
nums <- unlist(lapply(data, is.numeric))
names(data[, nums])  
ncol(names(data[, nums]))
numeric_cols <- data[, nums]

# 수치형 변수들과 Y에 대한 상관계수표 구하기
data_pearson = cbind(numeric_cols, Y=as.integer(data$Y))
str(data_pearson)
pearson <- as.data.frame(cor(data_pearson[, c(1:ncol(data_pearson))], use = "all.obs", method = "pearson"))

pearson_cor <- (pearson$Y)[-4]
names(pearson_cor) = c("age", "occupation", "income") 
```

# 예측변수 선정
결과 : 피어슨 상관계수에 있는 속성들은 전체적으로 그 상관도가 너무 낮아 선택하기 않기로 함.
예측 변수 7개 선택 : destination, passanger, weather, time, coupon, expiration
```{r}
# 타겟 변수 Y에 대한 두 상관계수 비교
as.data.frame(pearson_cor) # 피어슨 상관계수
as.data.frame(cramerV_cor) # 크래머 V 상관계수

## 예측변수 선택 - 상관계수 절대값 0.03(피어슨), 0.15(크래머) 이상인 속성들
pearson_cor <- pearson_cor[!is.na(pearson_cor)] # NA 제거 (표준편차가 0인 값들은 NA가 됨)

cat("피어슨 상관계수 - 절대값 큰 순서대로\n")
sort(pearson_cor[pearson_cor>=0],decreasing=TRUE)
sort(pearson_cor[pearson_cor<0])
cat("\n")
cat("크래머 상관계수 - 큰 순서대로\n")
sort(cramerV_cor,decreasing=TRUE)
cat("\n")

# 크래머 계수에서 0.1보다 큰 값 선택하기
cramerV_cor <- cramerV_cor[cramerV_cor>=0.1]
names(cramerV_cor)

# 데이터셋 재구성
temp <- data[, names(cramerV_cor)]
data <- cbind(temp, "Y"=data[, 'Y'])
data
boxplot(data)
```

# 데이터셋 분할 (3등분)
```{r}
# shuffle and split the data into three parts
set.seed(2022)
data <- data[sample(nrow(data)),]
split <- floor(nrow(data)/3)
ensembleData <- data[0:split,]
blenderData <- data[(split+1):(split*2),]
testingData <- data[(split*2+1):nrow(data),]

# set label name and predictors
labelName <- 'Y'
predictors <- names(ensembleData)[names(ensembleData) != labelName]
```

# 1. 단순 앙상블 모델 학습
```{r}
set.seed(2022)
library(caret)
# create a caret control object to control the number of cross-validations performed
myControl <- trainControl(method='cv', number=3, returnResamp='none')

# quick benchmark model 
test_model <- train(blenderData[,predictors], blenderData[,labelName], method='gbm', trControl=myControl)
preds <- predict(object=test_model, testingData[,predictors])

library(pROC)
auc <- roc(as.numeric(testingData[,labelName]), as.numeric(preds))
print(auc$auc) # Area under the curve: 0.675
plot.roc(auc, legacy.axes=TRUE, main="ROC Curve (gbm)",print.auc=T, print.auc.x=0.5, print.auc.y=0.5,)
```

# 2. 복합 앙상블 모델 학습 및 예측
```{r}
set.seed(2022)
# train all the ensemble models with ensembleData
model_gbm <- train(ensembleData[,predictors], ensembleData[,labelName], method='gbm', trControl=myControl)
model_rpart <- train(ensembleData[,predictors], ensembleData[,labelName], method='rpart', trControl=myControl)
model_ann <- train(ensembleData[,predictors],ensembleData[,labelName], method = 'nnet', trControl=myControl)
model_nb <- train(ensembleData[,predictors],ensembleData[,labelName], method = 'nb', trControl=myControl)
model_treebag <- train(ensembleData[,predictors], ensembleData[,labelName], method='treebag', trControl=myControl)

# get predictions for each ensemble model for two last data sets
# and add them back to themselves
blenderData$gbm_PROB <- predict(object=model_gbm, blenderData[,predictors])
blenderData$ann_PROB <- predict(object=model_ann, blenderData[,predictors])
blenderData$nb_PROB <- predict(object=model_nb, blenderData[,predictors])
blenderData$rf_PROB <- predict(object=model_rpart, blenderData[,predictors])
blenderData$treebag_PROB <- predict(object=model_treebag, blenderData[,predictors])

testingData$gbm_PROB <- predict(object=model_gbm, testingData[,predictors])
testingData$ann_PROB <- predict(object=model_ann, testingData[,predictors])
testingData$nb_PROB <- predict(object=model_nb, testingData[,predictors])
testingData$rf_PROB <- predict(object=model_rpart, testingData[,predictors])
testingData$treebag_PROB <- predict(object=model_treebag, testingData[,predictors])
```
# 3. 성능 분석
```{r}
# see how each individual model performed on its own
auc1 <- roc(as.numeric(testingData[,labelName]), as.numeric(testingData$gbm_PROB))
print(auc1$auc) # Area under the curve: 0.6888

auc2 <- roc(as.numeric(testingData[,labelName]), as.numeric(testingData$nb_PROB))
print(auc2$auc) # Area under the curve: 0.6488

auc3 <- roc(as.numeric(testingData[,labelName]), as.numeric(testingData$rf_PROB))
print(auc3$auc) # Area under the curve: 0.6389

auc4 <- roc(as.numeric(testingData[,labelName]), as.numeric(testingData$treebag_PROB))
print(auc4$auc) # Area under the curve: 0.6595


auc5 <- roc(as.numeric(testingData[,labelName]), as.numeric(testingData$ann_PROB))
print(auc5$auc) # Area under the curve: 0.6807

# run a final model to blend all the probabilities together
predictors <- names(blenderData)[names(blenderData) != labelName]
final_blender_model <- train(blenderData[,predictors], blenderData[,labelName], method='gbm', trControl=myControl)

# See final prediction and AUC of blended ensemble
preds <- predict(object=final_blender_model, testingData[,predictors])
auc <- roc(as.numeric(testingData[,labelName]), as.numeric(preds))
print(auc$auc)  # Area under the curve: 0.6875
```

# ROC plot
```{r}
plot.roc(auc1, legacy.axes=TRUE, main="ROC Curve", col="black", lwd=2, auc.polygon=T, auc.polygon.col="aliceblue", max.auc.polygon=T, print.auc=T, print.auc.x=0.5, print.auc.y=0.5, print.auc.cex=0.9)
plot.roc(auc2, legacy.axes=TRUE, add=T, col="orange2", lwd=2, print.auc=T, print.auc.x=0.5, print.auc.y=0.45, print.auc.cex=0.9)
plot.roc(auc3, legacy.axes=TRUE, add=T, col="blue", lwd=2, print.auc=T, print.auc.x=0.5, print.auc.y=0.4, print.auc.cex=0.9)
plot.roc(auc4, legacy.axes=TRUE, add=T, col="forestgreen", lwd=2, print.auc=T, print.auc.x=0.5, print.auc.y=0.35, print.auc.cex=0.9)
plot.roc(auc5, legacy.axes=TRUE, add=T, col="gold4", lwd=2, print.auc=T, print.auc.x=0.5, print.auc.y=0.3, print.auc.cex=0.9)
plot.roc(auc, legacy.axes=TRUE, add=T, col="red", lwd=2, print.auc=T, print.auc.x=0.5, print.auc.y=0.25, print.auc.cex=0.9)



legend(0.15, 0.55, legend=c("gbm", "nb", "rpart", "treeBag", "ann", "overall"), col=c("black", "orange2", "blue", "forestgreen", "gold4", "red"), cex=0.8, lty=1, lwd=2)
```