```{r}
df <-read.csv("Fish.csv",header = T)

```

```{r}
#install.packages("rsample")
library(rpart)         # Decision Tree
library(rpart.plot)    # Decision Tree plotting 
library(rsample)      # for 층화 추출
#install.packages("caret")
library(caret)
#install.packages("dplyr")
#install.packages("readr")
#install.packages("tidyr")
#install.packages(("Benchmarking"))
#install.packages("mice")
library(dplyr)
library(readr)
library(tidyr)
library(Benchmarking)
library(mice)
```
```{r}
##df의 size
dim(df)
```
```{r}
##duplicated 함수를 이요한 중복 값 확인
##중복값은 없음을 알 수 있다.
df %>% duplicated()
duplicates <- df %>% duplicated() %>% table()
duplicates

##h distinct()함수를 이용해 중복값을 제거
## 총 17개의 변수 생략
df %>% distinct()

## 결측치 측정 
## 각 컬럼별 결측치는 포함되어 있지 않았다.
col_na <- function(y) {
  return(sum(is.na(y)))
}

na_count <- sapply(df, FUN = col_na)
na_count

##데이터셋의 깨지는 컬럼명을 변경
names(df)[1] <- c("Species")
head(df)
```


```{r}
print("데이터셋 요약")
summary(df)
```

```{r}
print("컬럼별 특징 보기")
str(df) # 컬럼별 특징 보기
```

```{r}
# loan_status를 기준으로                                               
split <- initial_split(data = df, 0.7, strata = "Species")



# trained data 
train <- training(split)

# test data 
test <- testing(split)
```

```{r}
print("### 훈련용 데이터 정보 ###")
summary(train)
str(train)

print("### 테스트용 데이터 정보 ###")
summary(test)
str(test)
```

```{r}
# 의사결정 함수 만들기 + 실행하기 + 모델시각화
train_dt <- function(data_csv)
{
  train.control<-rpart.control(xval = 10, minsplit = 2, minbucket=1, maxdepth=3)
  result <- rpart(Species ~ ., data = df, method="class", control=train.control)
  return(result)
}

# 실행
train_dt(train)
# 시각화
rpart.plot(train_dt(train), roundint = FALSE)
```

```{r}
#예측하기
Status_predict <- predict(train_dt(train), test, type = "class")
Status_predict
```

```{r}
#평가하기

# 실제 데이터의 대출 상환 여부부
actual <- test$Species

# 비교하고 정확도 계산
confusionMatrix(as.factor(actual), Status_predict, positive = 'Yes')
```

```{r}
tree <- train_dt(train)
tree$control
tree$cptable
opt <- which.min(tree$cptable[, "xerror"]) #오류률이 제일 적은 CP값 탐색색
cp <- tree$cptable[opt, "CP"] #cp 최적화 값
plotcp(tree)
print(cp)
pruned_tree <- prune(tree, cp = cp) #cp =0.1로 가지치기`
rpart.plot(pruned_tree, box.palette = "pink", roundint = F)

# 예측하기
Status_predict <- predict(pruned_tree, test, type = "class")

# 실제 데이터의 정당
actual <- test$癤풱pecies

# 비교하고 정확도 계산
confusionMatrix(as.factor(actual), Status_predict, positive = 'Yes')
```

``` {r}
# Rule Set 추출

#install.packages("rpart.plot")
library(rpart.plot)

rule0 <- rpart.rules(x=train_dt(train))
#rule1 <- rpart.rules(train_dt(train), cover=TRUE, nn=TRUE)
#rule2 <- rpart.rules(train_dt(train), nn=TRUE)  # 각 rule의 leaf node 개수 표시
rule3 <- rpart.rules(x=train_dt(train), cover=TRUE) # 각 rule에 의해 커버되는 케이스의 비율을 출력 (중요한 rule)
```

